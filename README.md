# Web-Scrapping

# Tools Used:
 Python : The primary programming language used for data analysis and modeling.
 BeautifulSoup : For HTML parsing
 Requests : For HTTP requests
 Pandas : For data manipulation and preprocessing.
 Jupyter Notebook : As the development environment for coding and documentation.

# Working Procedure:

 Environment Setup:
1. Install required libraries (BeautifulSoup, Requests, Pandas) using pip.
 Script Development:
1. Develop a Python script file titled webscrap.py.
2. Add library imports at the beginning of the file.
 Sending Requests:
1. Use the Requests library to send HTTP requests on target web pages.
2. Use exceptions in case receiving errors while sending requests.
 Parsing HTML:
1. Use BeautifulSoup to parse web page HTML.
2. Travel down the hierarchy of HTML to get required information and acquire it.
 Data Storage:
1. Clean and categorize the data that has been extracted.
2. Employ Pandas to structure the data into DataFrame to facilitate manipulation and
exportation.
 Exporting Data:
1. Export the scraped data to CSV or Excel files for analysis.
 Testing and Validation:
1. Execute the script on a diverse range of web pages to check for accuracy.
2. Verify the extracted data for relevance and completeness.

# Learning Outcomes:

 Understanding Web Scraping
Understand the fundamentals of web scraping and data extraction.
 Practical Application of Libraries:
Master the application of Python libraries such as BeautifulSoup and Requests for the
purpose of carrying out web scraping operations.
 Handling Skills of Data:
Understand data cleaning, handling, and storage with the help of Pandas.
 Problem-Solving: Understand de
